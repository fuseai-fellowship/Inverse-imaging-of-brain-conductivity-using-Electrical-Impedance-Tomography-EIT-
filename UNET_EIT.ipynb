{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaGXjwiL3D3S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import h5py\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class AttentionBlock(layers.Layer):\n",
        "    \"\"\"Attention gate for U-Net\"\"\"\n",
        "    def __init__(self, filters):\n",
        "        super().__init__()\n",
        "        self.W_g = layers.Conv2D(filters, 1, padding='same')\n",
        "        self.W_x = layers.Conv2D(filters, 1, padding='same')\n",
        "        self.psi = layers.Conv2D(1, 1, padding='same', activation='sigmoid')\n",
        "\n",
        "    def call(self, g, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            g: gating signal from decoder (coarser scale)\n",
        "            x: skip connection from encoder (finer scale)\n",
        "        \"\"\"\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.psi(layers.Activation('relu')(g1 + x1))\n",
        "        return x * psi\n",
        "\n",
        "\n",
        "class EITDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Efficient data generator for HDF5 EIT dataset\"\"\"\n",
        "\n",
        "    def __init__(self, h5_path, batch_size=16, shuffle=True, max_measurements=None):\n",
        "        self.h5_path = h5_path\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        with h5py.File(h5_path, 'r') as f:\n",
        "            self.n_samples = len(f['difference'])\n",
        "\n",
        "            # Compute GLOBAL max measurements across ALL samples\n",
        "            if max_measurements is None:\n",
        "                max_len = 0\n",
        "                for i in range(self.n_samples):\n",
        "                    diff = np.array(f['difference'][i])\n",
        "                    max_len = max(max_len, len(diff))\n",
        "                self.max_measurements = max_len\n",
        "            else:\n",
        "                self.max_measurements = max_measurements\n",
        "\n",
        "        # Compute global normalization statistics (stable approach)\n",
        "        print(f\"Computing normalization statistics from {min(1000, self.n_samples)} samples...\")\n",
        "        with h5py.File(self.h5_path, 'r') as f:\n",
        "            n_samples_for_stats = min(1000, self.n_samples)\n",
        "\n",
        "            # Collect voltage difference features\n",
        "            sample_features = []\n",
        "            for i in range(n_samples_for_stats):\n",
        "                v_diff = np.array(f['difference'][i])\n",
        "                features = np.concatenate([np.real(v_diff), np.imag(v_diff)])\n",
        "                # Pad to max_measurements * 2\n",
        "                if len(features) < self.max_measurements * 2:\n",
        "                    features = np.pad(features, (0, self.max_measurements * 2 - len(features)))\n",
        "                sample_features.append(features)\n",
        "\n",
        "            all_features = np.concatenate(sample_features)\n",
        "            self.X_mean = all_features.mean()\n",
        "            self.X_std = all_features.std() + 1e-8  # Add epsilon for stability\n",
        "\n",
        "            # Collect ground truth statistics\n",
        "            sample_gts = np.array([f['gt_difference'][i] for i in range(n_samples_for_stats)])\n",
        "            self.y_mean = sample_gts.mean()\n",
        "            self.y_std = sample_gts.std() + 1e-8  # Add epsilon for stability\n",
        "\n",
        "        print(f\"Normalization stats - X: mean={self.X_mean:.4f}, std={self.X_std:.4f}\")\n",
        "        print(f\"Normalization stats - y: mean={self.y_mean:.4f}, std={self.y_std:.4f}\")\n",
        "\n",
        "        self.indices = np.arange(self.n_samples)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.n_samples / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        with h5py.File(self.h5_path, 'r') as f:\n",
        "            # Load voltage difference directly\n",
        "            v_diff = [np.array(f['difference'][i]) for i in batch_indices]\n",
        "\n",
        "            # Split complex into real + imaginary and pad\n",
        "            inputs = []\n",
        "            for vd in v_diff:\n",
        "                features = np.concatenate([np.real(vd), np.imag(vd)])\n",
        "                # Pad to max_measurements * 2\n",
        "                if len(features) < self.max_measurements * 2:\n",
        "                    features = np.pad(features, (0, self.max_measurements * 2 - len(features)))\n",
        "                inputs.append(features)\n",
        "\n",
        "            X = np.array(inputs)\n",
        "\n",
        "            # Load gt_difference as target\n",
        "            y = np.array([f['gt_difference'][i] for i in batch_indices])\n",
        "            y = y[..., np.newaxis]\n",
        "\n",
        "        # Normalize using pre-computed statistics\n",
        "        X = (X - self.X_mean) / self.X_std\n",
        "        y = (y - self.y_mean) / self.y_std\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "\n",
        "def build_attention_unet(input_shape, output_shape=(128, 128, 1), filters_base=64):\n",
        "    \"\"\"Build U-Net with Attention architecture\"\"\"\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial dense layer to reshape voltage measurements to 2D\n",
        "    dense_size = 128 * 128  # Match your grid_size\n",
        "    x = layers.Dense(dense_size, activation='relu')(inputs)\n",
        "    x = layers.Reshape((128, 128, 1))(x)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(filters_base, 3, activation='relu', padding='same')(x)\n",
        "    conv1 = layers.BatchNormalization()(conv1)\n",
        "    conv1 = layers.Conv2D(filters_base, 3, activation='relu', padding='same')(conv1)\n",
        "    conv1 = layers.BatchNormalization()(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(filters_base*2, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.BatchNormalization()(conv2)\n",
        "    conv2 = layers.Conv2D(filters_base*2, 3, activation='relu', padding='same')(conv2)\n",
        "    conv2 = layers.BatchNormalization()(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(filters_base*4, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.BatchNormalization()(conv3)\n",
        "    conv3 = layers.Conv2D(filters_base*4, 3, activation='relu', padding='same')(conv3)\n",
        "    conv3 = layers.BatchNormalization()(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(filters_base*8, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = layers.BatchNormalization()(conv4)\n",
        "    conv4 = layers.Conv2D(filters_base*8, 3, activation='relu', padding='same')(conv4)\n",
        "    conv4 = layers.BatchNormalization()(conv4)\n",
        "    drop4 = layers.Dropout(0.5)(conv4)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv5 = layers.Conv2D(filters_base*16, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = layers.BatchNormalization()(conv5)\n",
        "    conv5 = layers.Conv2D(filters_base*16, 3, activation='relu', padding='same')(conv5)\n",
        "    conv5 = layers.BatchNormalization()(conv5)\n",
        "    drop5 = layers.Dropout(0.5)(conv5)\n",
        "\n",
        "    # Decoder with Attention\n",
        "    up6 = layers.Conv2DTranspose(filters_base*8, 2, strides=(2, 2), padding='same')(drop5)\n",
        "    att6 = AttentionBlock(filters_base*8)(up6, drop4)\n",
        "    merge6 = layers.concatenate([att6, up6], axis=3)\n",
        "    conv6 = layers.Conv2D(filters_base*8, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = layers.BatchNormalization()(conv6)\n",
        "    conv6 = layers.Conv2D(filters_base*8, 3, activation='relu', padding='same')(conv6)\n",
        "    conv6 = layers.BatchNormalization()(conv6)\n",
        "\n",
        "    up7 = layers.Conv2DTranspose(filters_base*4, 2, strides=(2, 2), padding='same')(conv6)\n",
        "    att7 = AttentionBlock(filters_base*4)(up7, conv3)\n",
        "    merge7 = layers.concatenate([att7, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(filters_base*4, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = layers.BatchNormalization()(conv7)\n",
        "    conv7 = layers.Conv2D(filters_base*4, 3, activation='relu', padding='same')(conv7)\n",
        "    conv7 = layers.BatchNormalization()(conv7)\n",
        "\n",
        "    up8 = layers.Conv2DTranspose(filters_base*2, 2, strides=(2, 2), padding='same')(conv7)\n",
        "    att8 = AttentionBlock(filters_base*2)(up8, conv2)\n",
        "    merge8 = layers.concatenate([att8, up8], axis=3)\n",
        "    conv8 = layers.Conv2D(filters_base*2, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = layers.BatchNormalization()(conv8)\n",
        "    conv8 = layers.Conv2D(filters_base*2, 3, activation='relu', padding='same')(conv8)\n",
        "    conv8 = layers.BatchNormalization()(conv8)\n",
        "\n",
        "    up9 = layers.Conv2DTranspose(filters_base, 2, strides=(2, 2), padding='same')(conv8)\n",
        "    att9 = AttentionBlock(filters_base)(up9, conv1)\n",
        "    merge9 = layers.concatenate([att9, up9], axis=3)\n",
        "    conv9 = layers.Conv2D(filters_base, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = layers.BatchNormalization()(conv9)\n",
        "    conv9 = layers.Conv2D(filters_base, 3, activation='relu', padding='same')(conv9)\n",
        "    conv9 = layers.BatchNormalization()(conv9)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(1, 1, activation='linear')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def eit_loss(y_true, y_pred):\n",
        "    \"\"\"Combined loss for EIT reconstruction with safety checks\"\"\"\n",
        "    # MSE loss\n",
        "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "    # Gradient loss (edge preservation for irregular anomalies)\n",
        "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
        "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
        "    grad_loss = tf.reduce_mean(tf.square(dy_true - dy_pred) + tf.square(dx_true - dx_pred))\n",
        "\n",
        "    # SSIM loss (structural similarity) with safety checks\n",
        "    # Compute dynamic max_val from data range\n",
        "    max_val = tf.reduce_max(y_true) - tf.reduce_min(y_true) + 1e-8\n",
        "    max_val = tf.clip_by_value(max_val, 1e-8, 10.0)  # Reasonable range for normalized data\n",
        "\n",
        "    ssim_val = tf.image.ssim(y_true, y_pred, max_val=max_val)\n",
        "    ssim_val = tf.clip_by_value(ssim_val, 0.0, 1.0)  # Ensure valid range\n",
        "    ssim_loss = 1.0 - tf.reduce_mean(ssim_val)\n",
        "\n",
        "    # Combine losses with balanced weights\n",
        "    total_loss = mse + 0.1 * grad_loss + 0.1 * ssim_loss\n",
        "\n",
        "    # Safety check: return MSE if total_loss is invalid\n",
        "    return tf.where(tf.math.is_finite(total_loss), total_loss, mse)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eit_model(train_path, val_path, test_path, epochs=100, batch_size=16, resume_from=None):\n",
        "    \"\"\"Complete training pipeline with validation\"\"\"\n",
        "\n",
        "    # Create data generators\n",
        "    train_gen = EITDataGenerator(train_path, batch_size=batch_size, shuffle=True)\n",
        "    val_gen = EITDataGenerator(\n",
        "        val_path,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        max_measurements=train_gen.max_measurements\n",
        "    )\n",
        "    test_gen = EITDataGenerator(\n",
        "        test_path,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        max_measurements=train_gen.max_measurements\n",
        "    )\n",
        "\n",
        "    # Build model\n",
        "    input_shape = (train_gen.max_measurements * 2,)\n",
        "    model = build_attention_unet(input_shape, output_shape=(128, 128, 1))\n",
        "\n",
        "    # Load checkpoint if resuming\n",
        "    if resume_from and Path(resume_from).exists():\n",
        "        print(f\"Loading checkpoint from {resume_from}\")\n",
        "        model.load_weights(resume_from)\n",
        "\n",
        "    # Compile with gradient clipping for stability\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0),\n",
        "        loss=eit_loss,\n",
        "        metrics=['mae', 'mse']\n",
        "    )\n",
        "\n",
        "    # Print model summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"U-Net with Attention Architecture\")\n",
        "    print(\"=\"*60)\n",
        "    model.summary()\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_attention_unet_eit.keras',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=10,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=20,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.CSVLogger('training_log.csv')\n",
        "    ]\n",
        "\n",
        "    # Train\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Starting Training...\")\n",
        "    print(\"=\"*60)\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history, train_gen, val_gen, test_gen\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EIT Brain Imaging - U-Net with Attention Training\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Train model\n",
        "    model, history, train_gen, val_gen, test_gen = train_eit_model(\n",
        "        train_path='/content/drive/MyDrive/brain_eit_training/brain_eit_dataset.h5',\n",
        "        val_path='/content/drive/MyDrive/brain_eit_validation/brain_eit_dataset.h5',\n",
        "        test_path='/content/drive/MyDrive/brain_eit_test/brain_eit_dataset.h5',\n",
        "        epochs=100,\n",
        "        batch_size=16\n",
        "    )\n",
        "\n",
        "    # Save final model\n",
        "    model.save('eit_attention_unet_final.keras')\n",
        "    print(\"\\n✓ Training complete! Model saved to eit_attention_unet_final.keras\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Evaluating on Test Set...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_results = model.evaluate(test_gen, verbose=1)\n",
        "    print(f\"\\nTest Loss: {test_results[0]:.4f}\")\n",
        "    print(f\"Test MAE: {test_results[1]:.4f}\")\n",
        "    print(f\"Test MSE: {test_results[2]:.4f}\")\n",
        "\n",
        "    # Plot training history\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Generating Training History Plots...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history.history['mae'], label='Training MAE')\n",
        "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MAE')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation MAE')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history.history['mse'], label='Training MSE')\n",
        "    plt.plot(history.history['val_mse'], label='Validation MSE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation MSE')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"Training history saved to training_history.png\")\n",
        "\n",
        "    # Generate sample predictions\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Generating Sample Predictions...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    with h5py.File('/content/drive/MyDrive/brain_eit_test/brain_eit_dataset.h5', 'r') as f:\n",
        "        for i in range(min(3, len(f['difference']))):\n",
        "            # Load data\n",
        "            v_diff = np.array(f['difference'][i])\n",
        "            gt = np.array(f['gt_difference'][i])\n",
        "\n",
        "            # Prepare input\n",
        "            features = np.concatenate([np.real(v_diff), np.imag(v_diff)])\n",
        "            if len(features) < train_gen.max_measurements * 2:\n",
        "                features = np.pad(features, (0, train_gen.max_measurements * 2 - len(features)))\n",
        "\n",
        "            # Normalize\n",
        "            features = (features - train_gen.X_mean) / (train_gen.X_std + 1e-8)\n",
        "            features = features.reshape(1, -1)\n",
        "\n",
        "            # Predict\n",
        "            pred = model.predict(features, verbose=0)[0, :, :, 0]\n",
        "\n",
        "            # Denormalize\n",
        "            pred = pred * (train_gen.y_std + 1e-8) + train_gen.y_mean\n",
        "\n",
        "            # Plot\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "            im0 = axes[0].imshow(gt, cmap='jet')\n",
        "            axes[0].set_title(f'Ground Truth (Sample {i})')\n",
        "            axes[0].axis('off')\n",
        "            plt.colorbar(im0, ax=axes[0])\n",
        "\n",
        "            im1 = axes[1].imshow(pred, cmap='jet')\n",
        "            axes[1].set_title(f'Prediction (Sample {i})')\n",
        "            axes[1].axis('off')\n",
        "            plt.colorbar(im1, ax=axes[1])\n",
        "\n",
        "            error = np.abs(gt - pred)\n",
        "            im2 = axes[2].imshow(error, cmap='hot')\n",
        "            axes[2].set_title(f'Absolute Error (Sample {i})')\n",
        "            axes[2].axis('off')\n",
        "            plt.colorbar(im2, ax=axes[2])\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'sample_prediction_{i}.png', dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "    print(f\"\\nSample predictions saved to sample_prediction_0.png, sample_prediction_1.png, sample_prediction_2.png\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"All Done!\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h8_J0spq3hhs",
        "outputId": "bcf3967d-9350-426f-fe4b-66f34ad96efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EIT Brain Imaging - U-Net with Attention Training\n",
            "============================================================\n",
            "Computing normalization statistics from 1000 samples...\n",
            "Normalization stats - X: mean=-0.0000, std=0.0160\n",
            "Normalization stats - y: mean=0.0011, std=0.0591\n",
            "Computing normalization statistics from 1000 samples...\n",
            "Normalization stats - X: mean=-0.0000, std=0.0137\n",
            "Normalization stats - y: mean=0.0022, std=0.0576\n",
            "Computing normalization statistics from 500 samples...\n",
            "Normalization stats - X: mean=-0.0000, std=0.0137\n",
            "Normalization stats - y: mean=0.0023, std=0.0597\n",
            "\n",
            "============================================================\n",
            "U-Net with Attention Architecture\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,832,128</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,825</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionBlock</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_block[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block_1   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,841</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionBlock</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_block_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block_2   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,153</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionBlock</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_block_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block_3   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,385</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionBlock</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_block_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)     │  \u001b[38;5;34m6,832,128\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m640\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,359,808\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │  \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │  \u001b[38;5;34m9,438,208\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,097,664\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m525,825\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mAttentionBlock\u001b[0m)    │ \u001b[38;5;34m512\u001b[0m)              │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ attention_block[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,359,808\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block_1   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,841\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mAttentionBlock\u001b[0m)    │ \u001b[38;5;34m256\u001b[0m)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ attention_block_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m)              │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │  \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block_2   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m33,153\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mAttentionBlock\u001b[0m)    │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ attention_block_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m32,832\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_block_3   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m8,385\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mAttentionBlock\u001b[0m)    │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ attention_block_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_transpose… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │         \u001b[38;5;34m65\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,585,477</span> (147.19 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,585,477\u001b[0m (147.19 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,573,701</span> (147.15 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,573,701\u001b[0m (147.15 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Starting Training...\n",
            "============================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: 1.3661 - mae: 0.4379 - mse: 1.2178\n",
            "Epoch 1: val_loss improved from inf to 2.47222, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 491ms/step - loss: 1.3649 - mae: 0.4376 - mse: 1.2168 - val_loss: 2.4722 - val_mae: 1.2192 - val_mse: 2.3722 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.4315 - mae: 0.2125 - mse: 0.3981\n",
            "Epoch 2: val_loss improved from 2.47222 to 1.71974, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 303ms/step - loss: 0.4314 - mae: 0.2124 - mse: 0.3980 - val_loss: 1.7197 - val_mae: 0.7757 - val_mse: 1.6405 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.3378 - mae: 0.1766 - mse: 0.3120\n",
            "Epoch 3: val_loss improved from 1.71974 to 0.42412, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 301ms/step - loss: 0.3377 - mae: 0.1766 - mse: 0.3120 - val_loss: 0.4241 - val_mae: 0.2012 - val_mse: 0.4001 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.2583 - mae: 0.1533 - mse: 0.2359\n",
            "Epoch 4: val_loss improved from 0.42412 to 0.33155, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 315ms/step - loss: 0.2584 - mae: 0.1533 - mse: 0.2360 - val_loss: 0.3316 - val_mae: 0.1663 - val_mse: 0.3122 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.2493 - mae: 0.1501 - mse: 0.2251\n",
            "Epoch 5: val_loss did not improve from 0.33155\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.2494 - mae: 0.1501 - mse: 0.2251 - val_loss: 0.3666 - val_mae: 0.1665 - val_mse: 0.3439 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.2304 - mae: 0.1462 - mse: 0.2071\n",
            "Epoch 6: val_loss did not improve from 0.33155\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 285ms/step - loss: 0.2304 - mae: 0.1462 - mse: 0.2071 - val_loss: 0.3932 - val_mae: 0.2303 - val_mse: 0.3511 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.2050 - mae: 0.1391 - mse: 0.1821\n",
            "Epoch 7: val_loss improved from 0.33155 to 0.27481, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 300ms/step - loss: 0.2050 - mae: 0.1391 - mse: 0.1821 - val_loss: 0.2748 - val_mae: 0.1352 - val_mse: 0.2571 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.1934 - mae: 0.1298 - mse: 0.1735\n",
            "Epoch 8: val_loss did not improve from 0.27481\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.1934 - mae: 0.1298 - mse: 0.1735 - val_loss: 0.2865 - val_mae: 0.1334 - val_mse: 0.2733 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.1888 - mae: 0.1326 - mse: 0.1676\n",
            "Epoch 9: val_loss improved from 0.27481 to 0.26240, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 303ms/step - loss: 0.1888 - mae: 0.1326 - mse: 0.1676 - val_loss: 0.2624 - val_mae: 0.1409 - val_mse: 0.2406 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1675 - mae: 0.1266 - mse: 0.1467\n",
            "Epoch 10: val_loss did not improve from 0.26240\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.1675 - mae: 0.1266 - mse: 0.1467 - val_loss: 0.3036 - val_mae: 0.1456 - val_mse: 0.2865 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1556 - mae: 0.1212 - mse: 0.1348\n",
            "Epoch 11: val_loss did not improve from 0.26240\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.1557 - mae: 0.1212 - mse: 0.1349 - val_loss: 0.3255 - val_mae: 0.1652 - val_mse: 0.3044 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.1575 - mae: 0.1215 - mse: 0.1362\n",
            "Epoch 12: val_loss did not improve from 0.26240\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 285ms/step - loss: 0.1575 - mae: 0.1215 - mse: 0.1362 - val_loss: 0.3617 - val_mae: 0.2422 - val_mse: 0.3180 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1454 - mae: 0.1211 - mse: 0.1237\n",
            "Epoch 13: val_loss improved from 0.26240 to 0.25710, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 329ms/step - loss: 0.1454 - mae: 0.1211 - mse: 0.1237 - val_loss: 0.2571 - val_mae: 0.1260 - val_mse: 0.2432 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.1397 - mae: 0.1199 - mse: 0.1187\n",
            "Epoch 14: val_loss did not improve from 0.25710\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.1397 - mae: 0.1199 - mse: 0.1187 - val_loss: 0.3492 - val_mae: 0.1524 - val_mse: 0.3308 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1271 - mae: 0.1121 - mse: 0.1077\n",
            "Epoch 15: val_loss did not improve from 0.25710\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.1271 - mae: 0.1122 - mse: 0.1077 - val_loss: 0.3465 - val_mae: 0.1454 - val_mse: 0.3328 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.1323 - mae: 0.1151 - mse: 0.1127\n",
            "Epoch 16: val_loss did not improve from 0.25710\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 285ms/step - loss: 0.1323 - mae: 0.1151 - mse: 0.1127 - val_loss: 0.2733 - val_mae: 0.1345 - val_mse: 0.2567 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1175 - mae: 0.1120 - mse: 0.0973\n",
            "Epoch 17: val_loss did not improve from 0.25710\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 285ms/step - loss: 0.1175 - mae: 0.1120 - mse: 0.0973 - val_loss: 0.3374 - val_mae: 0.1458 - val_mse: 0.3231 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1241 - mae: 0.1157 - mse: 0.1032\n",
            "Epoch 18: val_loss did not improve from 0.25710\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.1241 - mae: 0.1157 - mse: 0.1032 - val_loss: 0.2771 - val_mae: 0.1341 - val_mse: 0.2641 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1230 - mae: 0.1116 - mse: 0.1042\n",
            "Epoch 19: val_loss improved from 0.25710 to 0.25689, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 332ms/step - loss: 0.1230 - mae: 0.1116 - mse: 0.1041 - val_loss: 0.2569 - val_mae: 0.1269 - val_mse: 0.2451 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1133 - mae: 0.1100 - mse: 0.0947\n",
            "Epoch 20: val_loss improved from 0.25689 to 0.23695, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 333ms/step - loss: 0.1133 - mae: 0.1100 - mse: 0.0947 - val_loss: 0.2370 - val_mae: 0.1188 - val_mse: 0.2260 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0952 - mae: 0.1017 - mse: 0.0782\n",
            "Epoch 21: val_loss did not improve from 0.23695\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0952 - mae: 0.1017 - mse: 0.0782 - val_loss: 0.3544 - val_mae: 0.2152 - val_mse: 0.3212 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.1038 - mae: 0.1057 - mse: 0.0858\n",
            "Epoch 22: val_loss did not improve from 0.23695\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.1038 - mae: 0.1057 - mse: 0.0858 - val_loss: 0.2775 - val_mae: 0.1322 - val_mse: 0.2649 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0965 - mae: 0.1034 - mse: 0.0799\n",
            "Epoch 23: val_loss did not improve from 0.23695\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0965 - mae: 0.1034 - mse: 0.0799 - val_loss: 0.2854 - val_mae: 0.1275 - val_mse: 0.2745 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0911 - mae: 0.1025 - mse: 0.0749\n",
            "Epoch 24: val_loss did not improve from 0.23695\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0911 - mae: 0.1025 - mse: 0.0749 - val_loss: 0.2508 - val_mae: 0.1304 - val_mse: 0.2373 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0889 - mae: 0.1003 - mse: 0.0739\n",
            "Epoch 25: val_loss improved from 0.23695 to 0.23217, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 304ms/step - loss: 0.0889 - mae: 0.1003 - mse: 0.0739 - val_loss: 0.2322 - val_mae: 0.1182 - val_mse: 0.2213 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0894 - mae: 0.1009 - mse: 0.0745\n",
            "Epoch 26: val_loss improved from 0.23217 to 0.22857, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 324ms/step - loss: 0.0894 - mae: 0.1009 - mse: 0.0745 - val_loss: 0.2286 - val_mae: 0.1184 - val_mse: 0.2174 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0829 - mae: 0.0986 - mse: 0.0686\n",
            "Epoch 27: val_loss did not improve from 0.22857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0830 - mae: 0.0986 - mse: 0.0686 - val_loss: 0.2649 - val_mae: 0.1274 - val_mse: 0.2529 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0822 - mae: 0.0979 - mse: 0.0680\n",
            "Epoch 28: val_loss did not improve from 0.22857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0822 - mae: 0.0979 - mse: 0.0680 - val_loss: 0.2552 - val_mae: 0.1237 - val_mse: 0.2437 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0815 - mae: 0.0966 - mse: 0.0677\n",
            "Epoch 29: val_loss did not improve from 0.22857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0815 - mae: 0.0966 - mse: 0.0677 - val_loss: 0.2571 - val_mae: 0.1273 - val_mse: 0.2429 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0801 - mae: 0.0974 - mse: 0.0665\n",
            "Epoch 30: val_loss did not improve from 0.22857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0801 - mae: 0.0974 - mse: 0.0665 - val_loss: 0.2385 - val_mae: 0.1182 - val_mse: 0.2277 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0773 - mae: 0.0981 - mse: 0.0631\n",
            "Epoch 31: val_loss did not improve from 0.22857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0774 - mae: 0.0981 - mse: 0.0631 - val_loss: 0.2767 - val_mae: 0.1331 - val_mse: 0.2632 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0756 - mae: 0.0939 - mse: 0.0627\n",
            "Epoch 32: val_loss did not improve from 0.22857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0756 - mae: 0.0939 - mse: 0.0627 - val_loss: 0.2546 - val_mae: 0.1192 - val_mse: 0.2443 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0694 - mae: 0.0914 - mse: 0.0569\n",
            "Epoch 33: val_loss did not improve from 0.22857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0694 - mae: 0.0914 - mse: 0.0569 - val_loss: 0.2654 - val_mae: 0.1372 - val_mse: 0.2495 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0707 - mae: 0.0937 - mse: 0.0574\n",
            "Epoch 34: val_loss improved from 0.22857 to 0.22613, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 334ms/step - loss: 0.0708 - mae: 0.0937 - mse: 0.0574 - val_loss: 0.2261 - val_mae: 0.1121 - val_mse: 0.2158 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0735 - mae: 0.0944 - mse: 0.0606\n",
            "Epoch 35: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0736 - mae: 0.0944 - mse: 0.0606 - val_loss: 0.2320 - val_mae: 0.1206 - val_mse: 0.2195 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0766 - mae: 0.0990 - mse: 0.0622\n",
            "Epoch 36: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0766 - mae: 0.0990 - mse: 0.0622 - val_loss: 0.2684 - val_mae: 0.1219 - val_mse: 0.2583 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0692 - mae: 0.0933 - mse: 0.0560\n",
            "Epoch 37: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0692 - mae: 0.0933 - mse: 0.0560 - val_loss: 0.2487 - val_mae: 0.1270 - val_mse: 0.2341 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0709 - mae: 0.0964 - mse: 0.0576\n",
            "Epoch 38: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0709 - mae: 0.0964 - mse: 0.0576 - val_loss: 0.2491 - val_mae: 0.1180 - val_mse: 0.2401 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0715 - mae: 0.0964 - mse: 0.0581\n",
            "Epoch 39: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0715 - mae: 0.0964 - mse: 0.0581 - val_loss: 0.2877 - val_mae: 0.1372 - val_mse: 0.2734 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0684 - mae: 0.0923 - mse: 0.0560\n",
            "Epoch 40: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0684 - mae: 0.0923 - mse: 0.0560 - val_loss: 0.2427 - val_mae: 0.1266 - val_mse: 0.2298 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0626 - mae: 0.0908 - mse: 0.0503\n",
            "Epoch 41: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0626 - mae: 0.0908 - mse: 0.0503 - val_loss: 0.2313 - val_mae: 0.1151 - val_mse: 0.2202 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0599 - mae: 0.0881 - mse: 0.0482\n",
            "Epoch 42: val_loss did not improve from 0.22613\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0599 - mae: 0.0881 - mse: 0.0482 - val_loss: 0.2513 - val_mae: 0.1271 - val_mse: 0.2388 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0666 - mae: 0.0921 - mse: 0.0544\n",
            "Epoch 43: val_loss improved from 0.22613 to 0.21090, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 374ms/step - loss: 0.0666 - mae: 0.0921 - mse: 0.0544 - val_loss: 0.2109 - val_mae: 0.1147 - val_mse: 0.1976 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0708 - mae: 0.0965 - mse: 0.0575\n",
            "Epoch 44: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0708 - mae: 0.0965 - mse: 0.0575 - val_loss: 0.2335 - val_mae: 0.1150 - val_mse: 0.2228 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0589 - mae: 0.0878 - mse: 0.0475\n",
            "Epoch 45: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0589 - mae: 0.0878 - mse: 0.0475 - val_loss: 0.2153 - val_mae: 0.1050 - val_mse: 0.2060 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0622 - mae: 0.0903 - mse: 0.0501\n",
            "Epoch 46: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0622 - mae: 0.0903 - mse: 0.0501 - val_loss: 0.2299 - val_mae: 0.1165 - val_mse: 0.2193 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0620 - mae: 0.0904 - mse: 0.0498\n",
            "Epoch 47: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0620 - mae: 0.0904 - mse: 0.0498 - val_loss: 0.2199 - val_mae: 0.1121 - val_mse: 0.2091 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0621 - mae: 0.0919 - mse: 0.0498\n",
            "Epoch 48: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0621 - mae: 0.0919 - mse: 0.0498 - val_loss: 0.2335 - val_mae: 0.1130 - val_mse: 0.2243 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0562 - mae: 0.0848 - mse: 0.0455\n",
            "Epoch 49: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0562 - mae: 0.0848 - mse: 0.0455 - val_loss: 0.2221 - val_mae: 0.1123 - val_mse: 0.2132 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0553 - mae: 0.0856 - mse: 0.0442\n",
            "Epoch 50: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0553 - mae: 0.0856 - mse: 0.0442 - val_loss: 0.2161 - val_mae: 0.1103 - val_mse: 0.2075 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0534 - mae: 0.0845 - mse: 0.0427\n",
            "Epoch 51: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0534 - mae: 0.0845 - mse: 0.0427 - val_loss: 0.2356 - val_mae: 0.1192 - val_mse: 0.2243 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0604 - mae: 0.0932 - mse: 0.0473\n",
            "Epoch 52: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0604 - mae: 0.0932 - mse: 0.0473 - val_loss: 0.2807 - val_mae: 0.1246 - val_mse: 0.2690 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0543 - mae: 0.0869 - mse: 0.0432\n",
            "Epoch 53: val_loss did not improve from 0.21090\n",
            "\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0543 - mae: 0.0869 - mse: 0.0432 - val_loss: 0.3545 - val_mae: 0.1499 - val_mse: 0.3416 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0502 - mae: 0.0837 - mse: 0.0394\n",
            "Epoch 54: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0502 - mae: 0.0837 - mse: 0.0393 - val_loss: 0.2222 - val_mae: 0.1095 - val_mse: 0.2133 - learning_rate: 5.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0410 - mae: 0.0791 - mse: 0.0306\n",
            "Epoch 55: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0410 - mae: 0.0791 - mse: 0.0306 - val_loss: 0.2129 - val_mae: 0.1054 - val_mse: 0.2038 - learning_rate: 5.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0357 - mae: 0.0751 - mse: 0.0259\n",
            "Epoch 56: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0357 - mae: 0.0751 - mse: 0.0259 - val_loss: 0.2204 - val_mae: 0.1074 - val_mse: 0.2111 - learning_rate: 5.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0303 - mae: 0.0649 - mse: 0.0225\n",
            "Epoch 57: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0303 - mae: 0.0649 - mse: 0.0225 - val_loss: 0.2241 - val_mae: 0.1119 - val_mse: 0.2137 - learning_rate: 5.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0402 - mae: 0.0766 - mse: 0.0296\n",
            "Epoch 58: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0402 - mae: 0.0766 - mse: 0.0296 - val_loss: 0.2214 - val_mae: 0.1090 - val_mse: 0.2120 - learning_rate: 5.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0324 - mae: 0.0688 - mse: 0.0238\n",
            "Epoch 59: val_loss did not improve from 0.21090\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0324 - mae: 0.0688 - mse: 0.0238 - val_loss: 0.2151 - val_mae: 0.1096 - val_mse: 0.2058 - learning_rate: 5.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0369 - mae: 0.0752 - mse: 0.0271\n",
            "Epoch 60: val_loss improved from 0.21090 to 0.20856, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 296ms/step - loss: 0.0369 - mae: 0.0752 - mse: 0.0271 - val_loss: 0.2086 - val_mae: 0.1017 - val_mse: 0.2005 - learning_rate: 5.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0355 - mae: 0.0744 - mse: 0.0258\n",
            "Epoch 61: val_loss did not improve from 0.20856\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0355 - mae: 0.0744 - mse: 0.0258 - val_loss: 0.2106 - val_mae: 0.1069 - val_mse: 0.2014 - learning_rate: 5.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0353 - mae: 0.0744 - mse: 0.0256\n",
            "Epoch 62: val_loss did not improve from 0.20856\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 286ms/step - loss: 0.0353 - mae: 0.0744 - mse: 0.0256 - val_loss: 0.2224 - val_mae: 0.1075 - val_mse: 0.2135 - learning_rate: 5.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0407 - mae: 0.0821 - mse: 0.0293\n",
            "Epoch 63: val_loss did not improve from 0.20856\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0407 - mae: 0.0821 - mse: 0.0292 - val_loss: 0.2144 - val_mae: 0.1023 - val_mse: 0.2065 - learning_rate: 5.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0381 - mae: 0.0786 - mse: 0.0275\n",
            "Epoch 64: val_loss did not improve from 0.20856\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0381 - mae: 0.0786 - mse: 0.0275 - val_loss: 0.2201 - val_mae: 0.1056 - val_mse: 0.2113 - learning_rate: 5.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0384 - mae: 0.0789 - mse: 0.0274\n",
            "Epoch 65: val_loss did not improve from 0.20856\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0384 - mae: 0.0789 - mse: 0.0274 - val_loss: 0.2402 - val_mae: 0.1240 - val_mse: 0.2258 - learning_rate: 5.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0340 - mae: 0.0739 - mse: 0.0246\n",
            "Epoch 66: val_loss improved from 0.20856 to 0.20568, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 330ms/step - loss: 0.0340 - mae: 0.0739 - mse: 0.0246 - val_loss: 0.2057 - val_mae: 0.1015 - val_mse: 0.1970 - learning_rate: 5.0000e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0367 - mae: 0.0753 - mse: 0.0267\n",
            "Epoch 67: val_loss did not improve from 0.20568\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0367 - mae: 0.0753 - mse: 0.0267 - val_loss: 0.2309 - val_mae: 0.1203 - val_mse: 0.2173 - learning_rate: 5.0000e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0366 - mae: 0.0769 - mse: 0.0259\n",
            "Epoch 68: val_loss did not improve from 0.20568\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0366 - mae: 0.0769 - mse: 0.0259 - val_loss: 0.2116 - val_mae: 0.1048 - val_mse: 0.2022 - learning_rate: 5.0000e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0360 - mae: 0.0765 - mse: 0.0256\n",
            "Epoch 69: val_loss did not improve from 0.20568\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0360 - mae: 0.0765 - mse: 0.0256 - val_loss: 0.2193 - val_mae: 0.1132 - val_mse: 0.2078 - learning_rate: 5.0000e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0346 - mae: 0.0746 - mse: 0.0251\n",
            "Epoch 70: val_loss did not improve from 0.20568\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0346 - mae: 0.0746 - mse: 0.0251 - val_loss: 0.2103 - val_mae: 0.1053 - val_mse: 0.2012 - learning_rate: 5.0000e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0342 - mae: 0.0756 - mse: 0.0245\n",
            "Epoch 71: val_loss did not improve from 0.20568\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0342 - mae: 0.0756 - mse: 0.0245 - val_loss: 0.2146 - val_mae: 0.1073 - val_mse: 0.2051 - learning_rate: 5.0000e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0328 - mae: 0.0713 - mse: 0.0241\n",
            "Epoch 72: val_loss did not improve from 0.20568\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0328 - mae: 0.0713 - mse: 0.0241 - val_loss: 0.2207 - val_mae: 0.1123 - val_mse: 0.2089 - learning_rate: 5.0000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0369 - mae: 0.0780 - mse: 0.0263\n",
            "Epoch 73: val_loss did not improve from 0.20568\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0369 - mae: 0.0780 - mse: 0.0263 - val_loss: 0.2076 - val_mae: 0.0996 - val_mse: 0.1999 - learning_rate: 5.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0357 - mae: 0.0776 - mse: 0.0251\n",
            "Epoch 74: val_loss improved from 0.20568 to 0.20390, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 334ms/step - loss: 0.0357 - mae: 0.0776 - mse: 0.0251 - val_loss: 0.2039 - val_mae: 0.1036 - val_mse: 0.1942 - learning_rate: 5.0000e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.0367 - mae: 0.0774 - mse: 0.0263\n",
            "Epoch 75: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0367 - mae: 0.0774 - mse: 0.0263 - val_loss: 0.2301 - val_mae: 0.1072 - val_mse: 0.2214 - learning_rate: 5.0000e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0320 - mae: 0.0705 - mse: 0.0232\n",
            "Epoch 76: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0320 - mae: 0.0705 - mse: 0.0232 - val_loss: 0.2169 - val_mae: 0.1111 - val_mse: 0.2064 - learning_rate: 5.0000e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0370 - mae: 0.0781 - mse: 0.0270\n",
            "Epoch 77: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0370 - mae: 0.0781 - mse: 0.0270 - val_loss: 0.2218 - val_mae: 0.1154 - val_mse: 0.2091 - learning_rate: 5.0000e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0333 - mae: 0.0741 - mse: 0.0236\n",
            "Epoch 78: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0333 - mae: 0.0741 - mse: 0.0236 - val_loss: 0.2548 - val_mae: 0.1471 - val_mse: 0.2345 - learning_rate: 5.0000e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0288 - mae: 0.0663 - mse: 0.0206\n",
            "Epoch 79: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0288 - mae: 0.0663 - mse: 0.0206 - val_loss: 0.2111 - val_mae: 0.1026 - val_mse: 0.2025 - learning_rate: 5.0000e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0297 - mae: 0.0704 - mse: 0.0210\n",
            "Epoch 80: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0297 - mae: 0.0704 - mse: 0.0210 - val_loss: 0.2324 - val_mae: 0.1159 - val_mse: 0.2205 - learning_rate: 5.0000e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0295 - mae: 0.0685 - mse: 0.0212\n",
            "Epoch 81: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0295 - mae: 0.0685 - mse: 0.0212 - val_loss: 0.2159 - val_mae: 0.1076 - val_mse: 0.2067 - learning_rate: 5.0000e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0326 - mae: 0.0737 - mse: 0.0231\n",
            "Epoch 82: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0326 - mae: 0.0737 - mse: 0.0231 - val_loss: 0.2051 - val_mae: 0.1027 - val_mse: 0.1968 - learning_rate: 5.0000e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0305 - mae: 0.0710 - mse: 0.0217\n",
            "Epoch 83: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0305 - mae: 0.0710 - mse: 0.0217 - val_loss: 0.2235 - val_mae: 0.1180 - val_mse: 0.2096 - learning_rate: 5.0000e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0318 - mae: 0.0724 - mse: 0.0223\n",
            "Epoch 84: val_loss did not improve from 0.20390\n",
            "\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - loss: 0.0318 - mae: 0.0724 - mse: 0.0223 - val_loss: 0.2196 - val_mae: 0.1129 - val_mse: 0.2082 - learning_rate: 5.0000e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0311 - mae: 0.0711 - mse: 0.0219\n",
            "Epoch 85: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0311 - mae: 0.0711 - mse: 0.0219 - val_loss: 0.2046 - val_mae: 0.1002 - val_mse: 0.1963 - learning_rate: 2.5000e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0263 - mae: 0.0673 - mse: 0.0175\n",
            "Epoch 86: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0263 - mae: 0.0673 - mse: 0.0175 - val_loss: 0.2093 - val_mae: 0.1037 - val_mse: 0.2008 - learning_rate: 2.5000e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0266 - mae: 0.0677 - mse: 0.0179\n",
            "Epoch 87: val_loss did not improve from 0.20390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0266 - mae: 0.0677 - mse: 0.0179 - val_loss: 0.2082 - val_mae: 0.1011 - val_mse: 0.1999 - learning_rate: 2.5000e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0257 - mae: 0.0664 - mse: 0.0171\n",
            "Epoch 88: val_loss improved from 0.20390 to 0.20036, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 333ms/step - loss: 0.0257 - mae: 0.0664 - mse: 0.0171 - val_loss: 0.2004 - val_mae: 0.0993 - val_mse: 0.1921 - learning_rate: 2.5000e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0257 - mae: 0.0666 - mse: 0.0171\n",
            "Epoch 89: val_loss did not improve from 0.20036\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0257 - mae: 0.0666 - mse: 0.0171 - val_loss: 0.2170 - val_mae: 0.1068 - val_mse: 0.2071 - learning_rate: 2.5000e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0271 - mae: 0.0704 - mse: 0.0178\n",
            "Epoch 90: val_loss did not improve from 0.20036\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0271 - mae: 0.0704 - mse: 0.0178 - val_loss: 0.2101 - val_mae: 0.1041 - val_mse: 0.2012 - learning_rate: 2.5000e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.0242 - mae: 0.0640 - mse: 0.0161\n",
            "Epoch 91: val_loss improved from 0.20036 to 0.19872, saving model to best_attention_unet_eit.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 311ms/step - loss: 0.0243 - mae: 0.0640 - mse: 0.0161 - val_loss: 0.1987 - val_mae: 0.0998 - val_mse: 0.1904 - learning_rate: 2.5000e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0289 - mae: 0.0723 - mse: 0.0192\n",
            "Epoch 92: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0289 - mae: 0.0723 - mse: 0.0192 - val_loss: 0.2064 - val_mae: 0.1009 - val_mse: 0.1981 - learning_rate: 2.5000e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0262 - mae: 0.0665 - mse: 0.0175\n",
            "Epoch 93: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0262 - mae: 0.0665 - mse: 0.0175 - val_loss: 0.2070 - val_mae: 0.1050 - val_mse: 0.1979 - learning_rate: 2.5000e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0303 - mae: 0.0739 - mse: 0.0200\n",
            "Epoch 94: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0303 - mae: 0.0739 - mse: 0.0200 - val_loss: 0.2016 - val_mae: 0.0982 - val_mse: 0.1938 - learning_rate: 2.5000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0247 - mae: 0.0658 - mse: 0.0165\n",
            "Epoch 95: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0247 - mae: 0.0658 - mse: 0.0165 - val_loss: 0.2057 - val_mae: 0.1019 - val_mse: 0.1971 - learning_rate: 2.5000e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0274 - mae: 0.0703 - mse: 0.0182\n",
            "Epoch 96: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0274 - mae: 0.0703 - mse: 0.0182 - val_loss: 0.2065 - val_mae: 0.1040 - val_mse: 0.1975 - learning_rate: 2.5000e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0271 - mae: 0.0679 - mse: 0.0186\n",
            "Epoch 97: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0271 - mae: 0.0679 - mse: 0.0186 - val_loss: 0.2107 - val_mae: 0.1022 - val_mse: 0.2025 - learning_rate: 2.5000e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0270 - mae: 0.0690 - mse: 0.0181\n",
            "Epoch 98: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0270 - mae: 0.0690 - mse: 0.0181 - val_loss: 0.2024 - val_mae: 0.0988 - val_mse: 0.1944 - learning_rate: 2.5000e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.0225 - mae: 0.0599 - mse: 0.0153\n",
            "Epoch 99: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 289ms/step - loss: 0.0225 - mae: 0.0599 - mse: 0.0153 - val_loss: 0.2027 - val_mae: 0.1019 - val_mse: 0.1936 - learning_rate: 2.5000e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0231 - mae: 0.0636 - mse: 0.0153\n",
            "Epoch 100: val_loss did not improve from 0.19872\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 287ms/step - loss: 0.0231 - mae: 0.0636 - mse: 0.0153 - val_loss: 0.2085 - val_mae: 0.1044 - val_mse: 0.1993 - learning_rate: 2.5000e-05\n",
            "Restoring model weights from the end of the best epoch: 91.\n",
            "\n",
            "✓ Training complete! Model saved to eit_attention_unet_final.keras\n",
            "\n",
            "============================================================\n",
            "Evaluating on Test Set...\n",
            "============================================================\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 338ms/step - loss: 0.2290 - mae: 0.1112 - mse: 0.2200\n",
            "\n",
            "Test Loss: 0.2030\n",
            "Test MAE: 0.1027\n",
            "Test MSE: 0.1943\n",
            "\n",
            "============================================================\n",
            "Generating Training History Plots...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training history saved to training_history.png\n",
            "\n",
            "============================================================\n",
            "Generating Sample Predictions...\n",
            "============================================================\n",
            "\n",
            "Sample predictions saved to sample_prediction_0.png, sample_prediction_1.png, sample_prediction_2.png\n",
            "\n",
            "============================================================\n",
            "All Done!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "163KnJviHwsP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}